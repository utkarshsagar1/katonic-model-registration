{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46fafc9-1e7b-4bf4-a02c-6a4e836b8920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# =====================================================================\n",
    "# 1. Configuration \n",
    "# =====================================================================\n",
    "\n",
    "# CRITICAL: Use the exact MLflow Tracking URI for your environment\n",
    "MLFLOW_TRACKING_URI = \"http://asa-532836a6-18bc-4f86-8be4-dc52ae067fcb.kt-wast-app.svc.cluster.local:80\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "REGISTERED_MODEL_NAME = \"Meralco_Classification_Model\"\n",
    "MODEL_URI = f\"models:/{REGISTERED_MODEL_NAME}/latest\" \n",
    "\n",
    "print(f\"MLflow URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "print(f\"Targeting Model URI: {MODEL_URI}\")\n",
    "\n",
    "# CRITICAL: This is the exact 26-column order required by the PyCaret pipeline.\n",
    "REQUIRED_FEATURES = [\n",
    "    # 22 Input Features (Numerical)\n",
    "    'consumption_1.0', 'consumption_2.0', 'consumption_3.0', 'consumption_4.0', 'consumption_5.0', \n",
    "    'consumption_6.0', 'utilization_1.0', 'utilization_2.0', 'utilization_3.0', 'utilization_4.0', \n",
    "    'utilization_5.0', 'utilization_6.0', 'roc_utl_12', 'roc_utl_23', 'roc_utl_34', \n",
    "    'roc_utl_45', 'roc_utl_56', 'si_count', 'si_neg_count', 'si_pos_count', 'count_increase',\n",
    "    'roc_of_roc', \n",
    "    # 4 Metadata/Target Columns (Must be included, as they were in the original training data)\n",
    "    'Cluster', 'incident_date', 'tln', 'with_inc'\n",
    "]\n",
    "\n",
    "# =====================================================================\n",
    "# 2. Model Loading\n",
    "# =====================================================================\n",
    "\n",
    "print(\"\\n--- Starting Model Load ---\")\n",
    "try:\n",
    "    # Load the model using the pyfunc flavor\n",
    "    loaded_model = mlflow.pyfunc.load_model(MODEL_URI)\n",
    "    print(\"SUCCESS: Model successfully loaded from MLflow Registry!\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to load model from registry. Check URI and dependencies.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    # Raise the error if load fails (often due to platform/artifact issues)\n",
    "    raise\n",
    "\n",
    "# =====================================================================\n",
    "# 3. Create Sample Input Data (GUARANTEED ORDER)\n",
    "# =====================================================================\n",
    "\n",
    "N_SAMPLES = 5 \n",
    "sample_rows = []\n",
    "\n",
    "# Generate data for N_SAMPLES rows, ensuring features are added in the REQUIRED_FEATURES order\n",
    "for i in range(N_SAMPLES):\n",
    "    row_data = {}\n",
    "    for col in REQUIRED_FEATURES:\n",
    "        if col == 'Cluster':\n",
    "            row_data[col] = 0 # Integer type\n",
    "        elif col == 'tln':\n",
    "            row_data[col] = f\"TLN{random.randint(100, 999)}\" # String/Object type\n",
    "        elif col == 'with_inc':\n",
    "            row_data[col] = random.choice([0, 1]) # Integer type\n",
    "        elif col == 'incident_date':\n",
    "            # Use string representation for date to maximize compatibility with PyCaret pipeline\n",
    "            row_data[col] = datetime.datetime(2025, 10, i + 1).strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            # All 22 main features are numerical (float)\n",
    "            row_data[col] = random.uniform(0.1, 1000)\n",
    "\n",
    "    sample_rows.append(row_data)\n",
    "\n",
    "# Create DataFrame, forcing the column order using the 'columns' argument\n",
    "sample_input_df = pd.DataFrame(sample_rows, columns=REQUIRED_FEATURES)\n",
    "\n",
    "print(\"\\n--- Sample Input Data (Verified Order) ---\")\n",
    "print(f\"Columns in test data: {list(sample_input_df.columns)}\")\n",
    "print(sample_input_df.head())\n",
    "\n",
    "# =====================================================================\n",
    "# 4. Run Prediction (The Test)\n",
    "# =====================================================================\n",
    "\n",
    "print(\"\\n--- Running Prediction Test ---\")\n",
    "\n",
    "# The column order is guaranteed by the DataFrame constructor, but this line \n",
    "# is kept to visually confirm the enforcement:\n",
    "sample_input_df = sample_input_df[REQUIRED_FEATURES] \n",
    "\n",
    "predictions = loaded_model.predict(sample_input_df)\n",
    "\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(predictions)\n",
    "\n",
    "print(\"\\nTEST COMPLETE: Model is functional and available for deployment.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
