{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06009076-ad88-4038-94aa-74e3812870fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow URI set to: http://asa-c25d20a2-8350-4950-8064-1d8a819e702c.kt-wast-app.svc.cluster.local:80\n",
      "\n",
      "--- Downloading and Inspecting Artifacts ---\n",
      "FATAL ERROR: Failed to download or parse MLmodel file. Cannot proceed without manual file access.\n",
      "Details: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1516/1723212347.py:32: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.10.2/model-registry.html#migrating-from-stages\n",
      "  model_version = client.get_latest_versions(REGISTERED_MODEL_NAME, stages=None)[0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m model_version \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_latest_versions(REGISTERED_MODEL_NAME, stages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m run_id \u001b[38;5;241m=\u001b[39m model_version\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m---> 34\u001b[0m artifact_path \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_version\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martifacts/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# 1. Define local path and download the artifact (model folder)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m local_dir \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mmkdtemp()\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import yaml\n",
    "import tempfile\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# =====================================================================\n",
    "# 1. Configuration (Keep the same)\n",
    "# =====================================================================\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"http://asa-c25d20a2-8350-4950-8064-1d8a819e702c.kt-wast-app.svc.cluster.local:80\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "REGISTERED_MODEL_NAME = \"Meralco_Classification_Model\"\n",
    "\n",
    "print(f\"MLflow URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "\n",
    "# =====================================================================\n",
    "# 2. Extracting Required Schema by Downloading Artifacts (FINAL ATTEMPT)\n",
    "# =====================================================================\n",
    "\n",
    "print(\"\\n--- Downloading and Inspecting Artifacts ---\")\n",
    "try:\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    # Get the latest model version\n",
    "    # Note: Suppressing FutureWarning here for cleaner output\n",
    "    model_version = client.get_latest_versions(REGISTERED_MODEL_NAME, stages=None)[0]\n",
    "    run_id = model_version.run_id\n",
    "    \n",
    "    # The 'source' attribute contains the full path to the artifact folder, \n",
    "    # e.g., 'runs:/<run_id>/artifacts/model' or similar. \n",
    "    # We strip everything before the 'artifacts' folder name.\n",
    "    source_parts = model_version.source.split('artifacts/')\n",
    "    \n",
    "    # If 'artifacts/' is present, use the part after it. If not, assume the model \n",
    "    # artifact path is the final part of the URI (the model folder name itself).\n",
    "    if len(source_parts) > 1:\n",
    "        artifact_subdir = source_parts[-1].strip('/')\n",
    "    else:\n",
    "        # Fallback assumption: artifact path is just the model folder name ('model')\n",
    "        artifact_subdir = 'model' \n",
    "        \n",
    "    print(f\"Inferred Run ID: {run_id}\")\n",
    "    print(f\"Inferred Artifact Subdirectory: {artifact_subdir}\")\n",
    "    \n",
    "    # 1. Define local path and download the artifact (model folder)\n",
    "    local_dir = tempfile.mkdtemp()\n",
    "    print(f\"Downloading artifact to temporary local directory: {local_dir}\")\n",
    "\n",
    "    # Use the run_id and inferred artifact_subdir for the download\n",
    "    mlflow.artifacts.download_artifacts(\n",
    "        run_id=run_id, \n",
    "        artifact_path=artifact_subdir, \n",
    "        dst_path=local_dir\n",
    "    )\n",
    "    \n",
    "    # The MLmodel file is expected inside the downloaded folder\n",
    "    model_folder = os.path.join(local_dir, artifact_subdir)\n",
    "    mlmodel_path = os.path.join(model_folder, \"MLmodel\")\n",
    "\n",
    "    # If the direct path doesn't exist, it means artifact_subdir was incorrect, \n",
    "    # but the download still saved the artifact correctly. Let's find the MLmodel file.\n",
    "    if not os.path.exists(mlmodel_path):\n",
    "        # Recursively search for MLmodel in the local_dir\n",
    "        found = False\n",
    "        for root, dirs, files in os.walk(local_dir):\n",
    "            if \"MLmodel\" in files:\n",
    "                mlmodel_path = os.path.join(root, \"MLmodel\")\n",
    "                found = True\n",
    "                print(f\"MLmodel file found at: {mlmodel_path.replace(local_dir, '...')}\")\n",
    "                break\n",
    "        if not found:\n",
    "            raise FileNotFoundError(\"Could not locate the MLmodel file after downloading artifacts.\")\n",
    "\n",
    "\n",
    "    # 2. Read and parse the MLmodel YAML file\n",
    "    with open(mlmodel_path, 'r') as f:\n",
    "        mlmodel_config = yaml.safe_load(f)\n",
    "\n",
    "    # 3. Extract the required column order from the signature\n",
    "    import json\n",
    "    # Ensure the signature exists before accessing it\n",
    "    if 'signature' not in mlmodel_config or 'inputs' not in mlmodel_config['signature']:\n",
    "        raise KeyError(\"MLmodel file does not contain a valid input signature.\")\n",
    "        \n",
    "    input_schema_json = mlmodel_config['signature']['inputs']\n",
    "    schema_data = json.loads(input_schema_json)\n",
    "    \n",
    "    # The columns array is usually nested inside 'fields'\n",
    "    REQUIRED_FEATURES = [col['name'] for col in schema_data['fields']]\n",
    "\n",
    "    print(\"SUCCESS: Retrieved Model Input Schema from MLmodel artifact.\")\n",
    "    print(f\"Total Columns Required: {len(REQUIRED_FEATURES)}\")\n",
    "    print(\"--- Exact Required Feature Order ---\")\n",
    "    for i, col_name in enumerate(REQUIRED_FEATURES):\n",
    "        print(f\"  {i+1}. {col_name}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR: Failed to download, locate, or parse MLmodel file.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    raise\n",
    "\n",
    "# =====================================================================\n",
    "# 3. Create Sample Input Data (USING EXTRACTED ORDER)\n",
    "# =====================================================================\n",
    "\n",
    "N_SAMPLES = 5 \n",
    "sample_rows = []\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "    row_data = {}\n",
    "    for col in REQUIRED_FEATURES:\n",
    "        # Determine data type based on our knowledge of the 26 columns\n",
    "        if col == 'Cluster':\n",
    "            row_data[col] = 0\n",
    "        elif col == 'tln':\n",
    "            row_data[col] = f\"TLN{random.randint(100, 999)}\"\n",
    "        elif col == 'with_inc':\n",
    "            row_data[col] = random.choice([0, 1])\n",
    "        elif col == 'incident_date':\n",
    "            row_data[col] = pd.Timestamp(datetime.datetime(2025, 10, i + 1))\n",
    "        else:\n",
    "            # Assume all other features are the 22 numerical features (float)\n",
    "            row_data[col] = random.uniform(0.1, 1000)\n",
    "\n",
    "    sample_rows.append(row_data)\n",
    "\n",
    "# Create DataFrame, forcing the column order using the 'columns' argument\n",
    "sample_input_df = pd.DataFrame(sample_rows, columns=REQUIRED_FEATURES)\n",
    "\n",
    "print(\"\\n--- Sample Input Data (Generated with Schema Order) ---\")\n",
    "print(f\"Columns in test data: {list(sample_input_df.columns)}\")\n",
    "print(sample_input_df.head())\n",
    "\n",
    "# =====================================================================\n",
    "# 4. Run Prediction (The Test)\n",
    "# =====================================================================\n",
    "\n",
    "MODEL_URI = f\"models:/{REGISTERED_MODEL_NAME}/latest\" \n",
    "\n",
    "print(\"\\n--- Starting Model Load ---\")\n",
    "try:\n",
    "    loaded_model = mlflow.pyfunc.load_model(MODEL_URI)\n",
    "    print(\"SUCCESS: Model successfully loaded from MLflow Registry!\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to load model from registry.\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n--- Running Prediction Test ---\")\n",
    "predictions = loaded_model.predict(sample_input_df)\n",
    "\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(predictions)\n",
    "\n",
    "print(\"\\nTEST COMPLETE: Model is functional and available for deployment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399c11e-33da-41b4-9b1a-86fa147c2695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a12a52a-b3c7-4e5f-8a53-577f21eace90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
